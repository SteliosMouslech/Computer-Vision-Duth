{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "-8-iDTZf-uh_",
    "outputId": "10a8f310-41d7-4fc5-9035-342c498c6ac0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 49158     \n",
      "=================================================================\n",
      "Total params: 14,763,846\n",
      "Trainable params: 14,763,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import callbacks\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    " \n",
    "# Create the model\n",
    "model=models.Sequential()\n",
    "\n",
    "VGG= VGG16(include_top=False,input_shape=(128,128,3),weights='imagenet')\n",
    "\n",
    "model.add(VGG)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(6, activation = \"softmax\"))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NM6qKbyW9Sxd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "base_dir = '/kaggle/input/duth-cv-2019-2020-hw-4/vehicles'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JruvtdJE9aoW",
    "outputId": "5c881940-c6c8-472d-cfc5-c6d2ef8f3072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2494 images belonging to 6 classes.\n",
      "Found 311 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)\n",
    "       \n",
    "val_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# --------------------\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "# --------------------\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    # color_mode='grayscale',\n",
    "                                                    target_size=(128,128),\n",
    "                                                    shuffle=True)     \n",
    "# --------------------\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "# --------------------\n",
    "validation_generator =  val_datagen.flow_from_directory(validation_dir,\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='categorical',\n",
    "                                                        #  color_mode='grayscale',\n",
    "                                                         target_size=(128,128)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2RL4DHoz_oSs",
    "outputId": "be273bda-b488-43d0-e6aa-2100bd5d21ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "78/77 [==============================] - 29s 375ms/step - loss: 1.1265 - acc: 0.5682 - val_loss: 0.9272 - val_acc: 0.6881\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.92721, saving model to best.h5\n",
      "Epoch 2/50\n",
      "78/77 [==============================] - 24s 308ms/step - loss: 0.6611 - acc: 0.7510 - val_loss: 0.6257 - val_acc: 0.7846\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.92721 to 0.62572, saving model to best.h5\n",
      "Epoch 3/50\n",
      "78/77 [==============================] - 24s 306ms/step - loss: 0.5032 - acc: 0.8192 - val_loss: 0.4627 - val_acc: 0.7814\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.62572 to 0.46275, saving model to best.h5\n",
      "Epoch 4/50\n",
      "78/77 [==============================] - 24s 313ms/step - loss: 0.4028 - acc: 0.8549 - val_loss: 0.6409 - val_acc: 0.7685\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46275\n",
      "Epoch 5/50\n",
      "78/77 [==============================] - 24s 311ms/step - loss: 0.3304 - acc: 0.8769 - val_loss: 0.2031 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46275 to 0.20308, saving model to best.h5\n",
      "Epoch 6/50\n",
      "78/77 [==============================] - 24s 308ms/step - loss: 0.2643 - acc: 0.9118 - val_loss: 0.8615 - val_acc: 0.8039\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.20308\n",
      "Epoch 7/50\n",
      "78/77 [==============================] - 25s 315ms/step - loss: 0.2268 - acc: 0.9170 - val_loss: 0.2748 - val_acc: 0.8489\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.20308\n",
      "Epoch 8/50\n",
      "78/77 [==============================] - 24s 304ms/step - loss: 0.1798 - acc: 0.9443 - val_loss: 0.8237 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.20308\n",
      "Epoch 9/50\n",
      "78/77 [==============================] - 24s 312ms/step - loss: 0.1460 - acc: 0.9495 - val_loss: 0.6508 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.20308\n",
      "Epoch 10/50\n",
      "78/77 [==============================] - 24s 312ms/step - loss: 0.1363 - acc: 0.9559 - val_loss: 0.6491 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.20308\n",
      "Epoch 11/50\n",
      "78/77 [==============================] - 24s 307ms/step - loss: 0.0990 - acc: 0.9695 - val_loss: 0.9621 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.20308\n",
      "Epoch 12/50\n",
      "78/77 [==============================] - 25s 318ms/step - loss: 0.0860 - acc: 0.9739 - val_loss: 0.6124 - val_acc: 0.8199\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.20308\n",
      "Epoch 13/50\n",
      "78/77 [==============================] - 24s 308ms/step - loss: 0.0837 - acc: 0.9751 - val_loss: 0.2708 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20308\n",
      "Epoch 14/50\n",
      "78/77 [==============================] - 25s 316ms/step - loss: 0.0700 - acc: 0.9791 - val_loss: 0.7226 - val_acc: 0.8810\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.20308\n",
      "Epoch 15/50\n",
      "78/77 [==============================] - 24s 307ms/step - loss: 0.0628 - acc: 0.9828 - val_loss: 0.7035 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20308\n",
      "Epoch 16/50\n",
      "78/77 [==============================] - 24s 309ms/step - loss: 0.0522 - acc: 0.9848 - val_loss: 0.4589 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.20308\n",
      "Epoch 17/50\n",
      "78/77 [==============================] - 25s 321ms/step - loss: 0.0517 - acc: 0.9844 - val_loss: 0.1643 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.20308 to 0.16431, saving model to best.h5\n",
      "Epoch 18/50\n",
      "78/77 [==============================] - 24s 308ms/step - loss: 0.0465 - acc: 0.9852 - val_loss: 0.2068 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.16431\n",
      "Epoch 19/50\n",
      "78/77 [==============================] - 25s 322ms/step - loss: 0.0432 - acc: 0.9864 - val_loss: 1.1520 - val_acc: 0.8585\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.16431\n",
      "Epoch 20/50\n",
      "78/77 [==============================] - 24s 310ms/step - loss: 0.0425 - acc: 0.9880 - val_loss: 1.0040 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.16431\n",
      "Epoch 21/50\n",
      "78/77 [==============================] - 24s 313ms/step - loss: 0.0362 - acc: 0.9900 - val_loss: 0.9981 - val_acc: 0.8810\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16431\n",
      "Epoch 22/50\n",
      "78/77 [==============================] - 25s 316ms/step - loss: 0.0330 - acc: 0.9896 - val_loss: 1.7313 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.16431\n",
      "Epoch 23/50\n",
      "78/77 [==============================] - 24s 309ms/step - loss: 0.0243 - acc: 0.9944 - val_loss: 0.5269 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.16431\n",
      "Epoch 24/50\n",
      "78/77 [==============================] - 25s 321ms/step - loss: 0.0331 - acc: 0.9908 - val_loss: 0.3277 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.16431\n",
      "Epoch 25/50\n",
      "78/77 [==============================] - 24s 309ms/step - loss: 0.0215 - acc: 0.9936 - val_loss: 0.0724 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.16431 to 0.07235, saving model to best.h5\n",
      "Epoch 26/50\n",
      "78/77 [==============================] - 25s 317ms/step - loss: 0.0174 - acc: 0.9940 - val_loss: 0.2550 - val_acc: 0.8424\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.07235\n",
      "Epoch 27/50\n",
      "78/77 [==============================] - 25s 316ms/step - loss: 0.0264 - acc: 0.9920 - val_loss: 1.5897 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.07235\n",
      "Epoch 28/50\n",
      "78/77 [==============================] - 24s 310ms/step - loss: 0.0179 - acc: 0.9948 - val_loss: 0.9447 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.07235\n",
      "Epoch 29/50\n",
      "78/77 [==============================] - 25s 322ms/step - loss: 0.0150 - acc: 0.9956 - val_loss: 0.7530 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07235\n",
      "Epoch 30/50\n",
      "78/77 [==============================] - 24s 311ms/step - loss: 0.0189 - acc: 0.9952 - val_loss: 0.7526 - val_acc: 0.8006\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.07235\n",
      "Epoch 31/50\n",
      "78/77 [==============================] - 25s 323ms/step - loss: 0.0200 - acc: 0.9948 - val_loss: 0.5397 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07235\n",
      "Epoch 32/50\n",
      "78/77 [==============================] - 24s 312ms/step - loss: 0.0177 - acc: 0.9952 - val_loss: 0.6190 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.07235\n",
      "Epoch 33/50\n",
      "78/77 [==============================] - 24s 308ms/step - loss: 0.0165 - acc: 0.9948 - val_loss: 0.5414 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.07235\n",
      "Epoch 34/50\n",
      "78/77 [==============================] - 25s 318ms/step - loss: 0.0177 - acc: 0.9960 - val_loss: 1.8727 - val_acc: 0.8071\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.07235\n",
      "Epoch 35/50\n",
      "78/77 [==============================] - 24s 305ms/step - loss: 0.0204 - acc: 0.9952 - val_loss: 0.8612 - val_acc: 0.8810\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07235\n",
      "Epoch 36/50\n",
      "78/77 [==============================] - 25s 317ms/step - loss: 0.0145 - acc: 0.9948 - val_loss: 0.7029 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.07235\n",
      "Epoch 37/50\n",
      "78/77 [==============================] - 24s 308ms/step - loss: 0.0171 - acc: 0.9960 - val_loss: 0.6548 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07235\n",
      "Epoch 38/50\n",
      "78/77 [==============================] - 24s 307ms/step - loss: 0.0153 - acc: 0.9956 - val_loss: 0.7435 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07235\n",
      "Epoch 39/50\n",
      "78/77 [==============================] - 25s 324ms/step - loss: 0.0205 - acc: 0.9960 - val_loss: 0.0018 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.07235 to 0.00179, saving model to best.h5\n",
      "Epoch 40/50\n",
      "78/77 [==============================] - 24s 307ms/step - loss: 0.0119 - acc: 0.9976 - val_loss: 1.1101 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00179\n",
      "Epoch 41/50\n",
      "78/77 [==============================] - 25s 323ms/step - loss: 0.0120 - acc: 0.9968 - val_loss: 0.6178 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00179\n",
      "Epoch 42/50\n",
      "78/77 [==============================] - 24s 311ms/step - loss: 0.0202 - acc: 0.9944 - val_loss: 0.4954 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00179\n",
      "Epoch 43/50\n",
      "78/77 [==============================] - 24s 314ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.1710 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00179\n",
      "Epoch 44/50\n",
      "78/77 [==============================] - 25s 320ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.8532 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00179\n",
      "Epoch 45/50\n",
      "78/77 [==============================] - 24s 306ms/step - loss: 0.0117 - acc: 0.9968 - val_loss: 0.1780 - val_acc: 0.8875\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00179\n",
      "Epoch 46/50\n",
      "78/77 [==============================] - 25s 320ms/step - loss: 0.0137 - acc: 0.9960 - val_loss: 0.5955 - val_acc: 0.8810\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00179\n",
      "Epoch 47/50\n",
      "78/77 [==============================] - 24s 303ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.2897 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00179\n",
      "Epoch 48/50\n",
      "78/77 [==============================] - 24s 311ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 0.1518 - val_acc: 0.8842\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00179\n",
      "Epoch 49/50\n",
      "78/77 [==============================] - 25s 314ms/step - loss: 0.0087 - acc: 0.9980 - val_loss: 0.7871 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00179\n",
      "Epoch 50/50\n",
      "78/77 [==============================] - 24s 304ms/step - loss: 0.0128 - acc: 0.9980 - val_loss: 0.3653 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00179\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "              metrics=['acc'])\n",
    "# Train the model\n",
    "callbacks = callback = callbacks.ModelCheckpoint(\"best.h5\", monitor='val_loss', mode = 'min', verbose=1, save_best_only = True)\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=train_generator.samples/train_generator.batch_size ,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
    "      verbose=1,callbacks=[callbacks])\n",
    " \n",
    "# Save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import image\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "model = tf.keras.models.load_model('/kaggle/working/best.h5')\n",
    "rowlist = [['Id', 'Category']]\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input/duth-cv-2019-2020-hw-4/vehicles/test'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)\n",
    "        img = image.load_img(path, target_size=(128, 128), grayscale=False, interpolation='bilinear')\n",
    "        \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        classes_pred = model.predict(x)\n",
    "        cls_pred = np.argmax(classes_pred)\n",
    "        rowlist.append([filename, cls_pred])\n",
    "        #print(filename, cls_pred)\n",
    "        with open('output.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerows(rowlist)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CV_2019-2020_Pretrained_Models_VGG.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
